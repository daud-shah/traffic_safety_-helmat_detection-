{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-14T08:24:44.577358Z",
     "iopub.status.busy": "2025-08-14T08:24:44.576975Z",
     "iopub.status.idle": "2025-08-14T08:25:18.542695Z",
     "shell.execute_reply": "2025-08-14T08:25:18.535075Z",
     "shell.execute_reply.started": "2025-08-14T08:24:44.577318Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.179 🚀 Python-3.10.18 torch-2.6.0+cu124 CPU (Intel Xeon 2.00GHz)\n",
      "Setup complete ✅ (96 CPUs, 334.6 GB RAM, 6410.9/8062.4 GB disk)\n"
     ]
    }
   ],
   "source": [
    "%pip install ultralytics\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T06:03:44.707419Z",
     "iopub.status.busy": "2025-08-14T06:03:44.707128Z",
     "iopub.status.idle": "2025-08-14T06:03:45.366046Z",
     "shell.execute_reply": "2025-08-14T06:03:45.361243Z",
     "shell.execute_reply.started": "2025-08-14T06:03:44.707394Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping wandb as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T06:03:47.637025Z",
     "iopub.status.busy": "2025-08-14T06:03:47.636729Z",
     "iopub.status.idle": "2025-08-14T06:04:10.005416Z",
     "shell.execute_reply": "2025-08-14T06:04:10.000797Z",
     "shell.execute_reply.started": "2025-08-14T06:03:47.636997Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\n",
      "  Downloading roboflow-1.2.6-py3-none-any.whl (88 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.6/88.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opencv-python-headless==4.10.0.84\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/site-packages (from roboflow) (6.0.2)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/site-packages (from roboflow) (2.9.0.post0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/site-packages (from roboflow) (2025.6.15)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/site-packages (from roboflow) (1.17.0)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/site-packages (from roboflow) (11.3.0)\n",
      "Collecting pillow-avif-plugin<2\n",
      "  Downloading pillow_avif_plugin-1.5.2-cp310-cp310-manylinux_2_28_x86_64.whl (4.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pi-heif<2\n",
      "  Downloading pi_heif-1.1.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting requests-toolbelt\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting idna==3.7\n",
      "  Downloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (from roboflow) (3.10.3)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/site-packages (from roboflow) (2.5.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from roboflow) (2.32.4)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/site-packages (from roboflow) (2.0.2)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/site-packages (from roboflow) (4.67.1)\n",
      "Requirement already satisfied: cycler in /usr/local/lib/python3.10/site-packages (from roboflow) (0.12.1)\n",
      "Collecting filetype\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from roboflow) (1.4.8)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib->roboflow) (4.58.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib->roboflow) (3.2.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib->roboflow) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib->roboflow) (25.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->roboflow) (3.4.2)\n",
      "Installing collected packages: pillow-avif-plugin, filetype, python-dotenv, pi-heif, opencv-python-headless, idna, requests-toolbelt, roboflow\n",
      "  Attempting uninstall: opencv-python-headless\n",
      "    Found existing installation: opencv-python-headless 4.11.0.86\n",
      "    Uninstalling opencv-python-headless-4.11.0.86:\n",
      "      Successfully uninstalled opencv-python-headless-4.11.0.86\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.10\n",
      "    Uninstalling idna-3.10:\n",
      "      Successfully uninstalled idna-3.10\n",
      "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pi-heif-1.1.0 pillow-avif-plugin-1.5.2 python-dotenv-1.1.1 requests-toolbelt-1.0.0 roboflow-1.2.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in helmate-1 to yolov8:: 100%|██████████| 258114/258114 [00:09<00:00, 28636.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to helmate-1 in yolov8:: 100%|██████████| 6118/6118 [00:01<00:00, 5771.22it/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"1BTvp0FPVcivYNLjzxn1\")\n",
    "project = rf.workspace(\"object-detection-sn8ac\").project(\"helmate-gxxio-emckf\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"yolov8\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-14T06:29:25.927Z",
     "iopub.execute_input": "2025-08-14T06:04:14.369287Z",
     "iopub.status.busy": "2025-08-14T06:04:14.368926Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov\n",
      "Ultralytics 8.3.179 🚀 Python-3.10.18 torch-2.6.0+cu124 CPU (Intel Xeon 2.00GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/helmate-1/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralyti\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2117209  ultralytics.nn.modules.head.Detect           [3, [128, 256, 512]]          \n",
      "Model summary: 129 layers, 11,136,761 parameters, 11,136,745 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1585.2±515.5 MB/s, size: 70.0 KB)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/helmate-1/train/labels... 2514 images, 8 backgro\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/helmate-1/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2193.9±411.3 MB/s, size: 89.9 KB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/helmate-1/valid/labels... 360 images, 0 background\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/helmate-1/valid/labels.cache\n",
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/50         0G      1.273      1.132      1.159         10        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        360       1663      0.898      0.832      0.893      0.536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/50         0G      1.274     0.8295      1.141          7        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        360       1663      0.864      0.806      0.869      0.531\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/50         0G       1.29     0.8274      1.148         98        640:  "
     ]
    }
   ],
   "source": [
    "# Train YOLOv8n on COCO8 for 50 epochs\n",
    "!yolo train model=yolov8s.pt data=\"/kaggle/working/helmate-1/data.yaml\" epochs=50 imgsz=640 batch=16 device=0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T08:35:13.820275Z",
     "iopub.status.busy": "2025-08-14T08:35:13.819797Z",
     "iopub.status.idle": "2025-08-14T08:35:17.522046Z",
     "shell.execute_reply": "2025-08-14T08:35:17.517096Z",
     "shell.execute_reply.started": "2025-08-14T08:35:13.820235Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/site-packages (8.3.179)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/site-packages (from ultralytics) (0.21.0)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/site-packages (from ultralytics) (3.10.3)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/site-packages (from ultralytics) (2.0.15)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/site-packages (from ultralytics) (1.15.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/site-packages (from ultralytics) (11.3.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/site-packages (from ultralytics) (2.3.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/site-packages (from ultralytics) (2.6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/site-packages (from ultralytics) (2.32.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.58.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2025.6.15)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.14.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2025.5.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics opencv-python numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T08:38:52.578353Z",
     "iopub.status.busy": "2025-08-14T08:38:52.577817Z",
     "iopub.status.idle": "2025-08-14T08:38:52.937397Z",
     "shell.execute_reply": "2025-08-14T08:38:52.933480Z",
     "shell.execute_reply.started": "2025-08-14T08:38:52.578284Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 1 motorcyclist, 230.5ms\n",
      "Speed: 5.2ms preprocess, 230.5ms inference, 7.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 motorcyclists, 148.7ms\n",
      "Speed: 3.6ms preprocess, 148.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 196.0ms\n",
      "Speed: 3.1ms preprocess, 196.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 motorcyclists, 207.1ms\n",
      "Speed: 2.7ms preprocess, 207.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 motorcyclists, 204.1ms\n",
      "Speed: 1.9ms preprocess, 204.1ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 251.0ms\n",
      "Speed: 2.6ms preprocess, 251.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 motorcyclists, 197.7ms\n",
      "Speed: 1.9ms preprocess, 197.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 motorcyclists, 200.5ms\n",
      "Speed: 3.1ms preprocess, 200.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 187.2ms\n",
      "Speed: 3.7ms preprocess, 187.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 189.5ms\n",
      "Speed: 3.5ms preprocess, 189.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 motorcyclists, 192.8ms\n",
      "Speed: 4.3ms preprocess, 192.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 motorcyclists, 199.8ms\n",
      "Speed: 2.5ms preprocess, 199.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 motorcyclists, 184.9ms\n",
      "Speed: 2.8ms preprocess, 184.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 motorcyclists, 189.3ms\n",
      "Speed: 3.2ms preprocess, 189.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 motorcyclists, 182.5ms\n",
      "Speed: 2.5ms preprocess, 182.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 motorcyclists, 177.2ms\n",
      "Speed: 2.1ms preprocess, 177.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 motorcyclists, 177.8ms\n",
      "Speed: 2.5ms preprocess, 177.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 motorcyclists, 185.9ms\n",
      "Speed: 3.5ms preprocess, 185.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 182.1ms\n",
      "Speed: 1.9ms preprocess, 182.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 179.5ms\n",
      "Speed: 3.4ms preprocess, 179.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 190.3ms\n",
      "Speed: 2.4ms preprocess, 190.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 186.2ms\n",
      "Speed: 2.0ms preprocess, 186.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 183.3ms\n",
      "Speed: 2.8ms preprocess, 183.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 221.3ms\n",
      "Speed: 2.9ms preprocess, 221.3ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 327.6ms\n",
      "Speed: 10.1ms preprocess, 327.6ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 336.0ms\n",
      "Speed: 3.0ms preprocess, 336.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 264.6ms\n",
      "Speed: 1.9ms preprocess, 264.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 motorcyclists, 316.2ms\n",
      "Speed: 3.6ms preprocess, 316.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 motorcyclists, 296.3ms\n",
      "Speed: 3.4ms preprocess, 296.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 282.2ms\n",
      "Speed: 2.1ms preprocess, 282.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 286.1ms\n",
      "Speed: 4.3ms preprocess, 286.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 279.2ms\n",
      "Speed: 2.2ms preprocess, 279.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 306.3ms\n",
      "Speed: 3.0ms preprocess, 306.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 283.3ms\n",
      "Speed: 6.5ms preprocess, 283.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 289.4ms\n",
      "Speed: 3.9ms preprocess, 289.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 257.9ms\n",
      "Speed: 2.6ms preprocess, 257.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 292.1ms\n",
      "Speed: 2.1ms preprocess, 292.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 motorcyclists, 299.8ms\n",
      "Speed: 3.4ms preprocess, 299.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 290.0ms\n",
      "Speed: 3.1ms preprocess, 290.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 287.8ms\n",
      "Speed: 3.1ms preprocess, 287.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 290.9ms\n",
      "Speed: 2.2ms preprocess, 290.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 290.9ms\n",
      "Speed: 3.0ms preprocess, 290.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 282.6ms\n",
      "Speed: 5.1ms preprocess, 282.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 246.8ms\n",
      "Speed: 2.4ms preprocess, 246.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 259.6ms\n",
      "Speed: 4.3ms preprocess, 259.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 291.8ms\n",
      "Speed: 4.3ms preprocess, 291.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 253.7ms\n",
      "Speed: 3.9ms preprocess, 253.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 276.1ms\n",
      "Speed: 1.9ms preprocess, 276.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 228.0ms\n",
      "Speed: 3.6ms preprocess, 228.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 207.6ms\n",
      "Speed: 2.8ms preprocess, 207.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 265.3ms\n",
      "Speed: 3.2ms preprocess, 265.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 249.9ms\n",
      "Speed: 2.1ms preprocess, 249.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 299.3ms\n",
      "Speed: 3.8ms preprocess, 299.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 235.8ms\n",
      "Speed: 2.1ms preprocess, 235.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 269.1ms\n",
      "Speed: 2.5ms preprocess, 269.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 249.9ms\n",
      "Speed: 2.4ms preprocess, 249.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 281.4ms\n",
      "Speed: 3.1ms preprocess, 281.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 261.6ms\n",
      "Speed: 2.3ms preprocess, 261.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 276.2ms\n",
      "Speed: 2.6ms preprocess, 276.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 286.2ms\n",
      "Speed: 2.9ms preprocess, 286.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 motorcyclists, 246.9ms\n",
      "Speed: 2.7ms preprocess, 246.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 275.1ms\n",
      "Speed: 3.5ms preprocess, 275.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 306.7ms\n",
      "Speed: 2.2ms preprocess, 306.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 motorcyclists, 226.8ms\n",
      "Speed: 2.4ms preprocess, 226.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 248.1ms\n",
      "Speed: 3.5ms preprocess, 248.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 281.9ms\n",
      "Speed: 3.0ms preprocess, 281.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 motorcyclists, 246.3ms\n",
      "Speed: 3.6ms preprocess, 246.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 motorcyclists, 267.2ms\n",
      "Speed: 4.4ms preprocess, 267.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 229.1ms\n",
      "Speed: 4.5ms preprocess, 229.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 232.5ms\n",
      "Speed: 2.4ms preprocess, 232.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 277.1ms\n",
      "Speed: 2.9ms preprocess, 277.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 helmet, 1 motorcyclist, 249.2ms\n",
      "Speed: 2.1ms preprocess, 249.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 267.9ms\n",
      "Speed: 1.7ms preprocess, 267.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 motorcyclists, 247.3ms\n",
      "Speed: 3.6ms preprocess, 247.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 helmet, 2 motorcyclists, 216.4ms\n",
      "Speed: 5.2ms preprocess, 216.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 motorcyclists, 238.5ms\n",
      "Speed: 4.0ms preprocess, 238.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 motorcyclists, 253.8ms\n",
      "Speed: 1.9ms preprocess, 253.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 motorcyclists, 325.3ms\n",
      "Speed: 1.9ms preprocess, 325.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 motorcyclists, 291.1ms\n",
      "Speed: 3.4ms preprocess, 291.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 motorcyclists, 180.9ms\n",
      "Speed: 2.9ms preprocess, 180.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 185.6ms\n",
      "Speed: 2.3ms preprocess, 185.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 helmet, 1 motorcyclist, 217.6ms\n",
      "Speed: 2.6ms preprocess, 217.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 203.6ms\n",
      "Speed: 2.0ms preprocess, 203.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 motorcyclists, 182.4ms\n",
      "Speed: 1.9ms preprocess, 182.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 motorcyclists, 215.2ms\n",
      "Speed: 2.4ms preprocess, 215.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 225.4ms\n",
      "Speed: 3.0ms preprocess, 225.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 241.7ms\n",
      "Speed: 2.6ms preprocess, 241.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 214.7ms\n",
      "Speed: 3.1ms preprocess, 214.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 205.0ms\n",
      "Speed: 2.4ms preprocess, 205.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 187.2ms\n",
      "Speed: 2.3ms preprocess, 187.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 190.2ms\n",
      "Speed: 1.9ms preprocess, 190.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 173.1ms\n",
      "Speed: 2.2ms preprocess, 173.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 175.6ms\n",
      "Speed: 2.6ms preprocess, 175.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 176.5ms\n",
      "Speed: 2.4ms preprocess, 176.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 motorcyclist, 187.5ms\n",
      "Speed: 1.8ms preprocess, 187.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Vertical video saved to C:\\Users\\Daud\\Downloads\\traffic_safety_yolov8\\1output_vertical.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class HelmetDetectionSystem:\n",
    "    def __init__(self, model_path, class_names):\n",
    "        \"\"\"\n",
    "        Initialize the helmet detection system with YOLO.\n",
    "        \n",
    "        Args:\n",
    "            model_path: Path to the trained YOLO model (.pt file)\n",
    "            class_names: List of class names in order [helmet, license_plate, motorcyclist]\n",
    "        \"\"\"\n",
    "        self.model = YOLO(model_path)\n",
    "        self.class_names = class_names\n",
    "        self.motorcyclist_index = class_names.index('motorcyclist')\n",
    "        self.helmet_index = class_names.index('helmet')\n",
    "        \n",
    "        # Detection colors\n",
    "        self.colors = {\n",
    "            'motorcyclist': (0, 255, 0),  # Green\n",
    "            'helmet': (0, 255, 0),       # Green\n",
    "            'no_helmet': (0, 0, 255),     # Red\n",
    "            'license_plate': (255, 0, 0)  # Blue\n",
    "        }\n",
    "    \n",
    "    def detect_objects(self, frame, confidence_threshold=0.5):\n",
    "        \"\"\"Detect objects in a frame using YOLO.\"\"\"\n",
    "        results = self.model(frame, conf=confidence_threshold)\n",
    "        detections = []\n",
    "        for result in results:\n",
    "            for box in result.boxes:\n",
    "                class_id = int(box.cls)\n",
    "                confidence = float(box.conf)\n",
    "                x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "                class_name = self.class_names[class_id]\n",
    "                box_coords = (x1, y1, x2-x1, y2-y1)\n",
    "                detections.append((class_name, confidence, box_coords))\n",
    "        return detections\n",
    "    \n",
    "    def process_frame(self, frame):\n",
    "        \"\"\"Process a single frame with vertical orientation.\"\"\"\n",
    "        # Rotate frame to vertical if width > height\n",
    "        if frame.shape[1] > frame.shape[0]:  # If width > height\n",
    "            frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "            \n",
    "        detections = self.detect_objects(frame)\n",
    "        motorcyclists = [d for d in detections if d[0] == 'motorcyclist']\n",
    "        \n",
    "        for motorcyclist in motorcyclists:\n",
    "            _, _, mc_box = motorcyclist\n",
    "            x, y, w, h = mc_box\n",
    "            cv2.rectangle(frame, (int(x), int(y)), (int(x+w), int(y+h)), \n",
    "                         self.colors['motorcyclist'], 2)\n",
    "            \n",
    "            has_helmet = False\n",
    "            for detection in detections:\n",
    "                class_name, _, h_box = detection\n",
    "                if class_name == 'helmet' and self._check_overlap(mc_box, h_box):\n",
    "                    has_helmet = True\n",
    "                    hx, hy, hw, hh = h_box\n",
    "                    cv2.rectangle(frame, (int(hx), int(hy)), (int(hx+hw), int(hy+hh)), \n",
    "                                 self.colors['helmet'], 2)\n",
    "                    break\n",
    "            \n",
    "            label = \"Helmet\" if has_helmet else \"No Helmet\"\n",
    "            color = self.colors['helmet'] if has_helmet else self.colors['no_helmet']\n",
    "            cv2.putText(frame, label, (int(x), int(y-10)), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "        \n",
    "        for detection in detections:\n",
    "            if detection[0] == 'license_plate':\n",
    "                x, y, w, h = detection[2]\n",
    "                cv2.rectangle(frame, (int(x), int(y)), (int(x+w), int(y+h)), \n",
    "                             self.colors['license_plate'], 2)\n",
    "                cv2.putText(frame, \"License Plate\", (int(x), int(y-10)), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, \n",
    "                           self.colors['license_plate'], 2)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def _check_overlap(self, box1, box2, overlap_threshold=0.5):\n",
    "        \"\"\"Check if two bounding boxes overlap significantly.\"\"\"\n",
    "        x_left = max(box1[0], box2[0])\n",
    "        y_top = max(box1[1], box2[1])\n",
    "        x_right = min(box1[0] + box1[2], box2[0] + box2[2])\n",
    "        y_bottom = min(box1[1] + box1[3], box2[1] + box2[3])\n",
    "        \n",
    "        if x_right < x_left or y_bottom < y_top:\n",
    "            return False\n",
    "            \n",
    "        intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "        box1_area = box1[2] * box1[3]\n",
    "        box2_area = box2[2] * box2[3]\n",
    "        overlap_ratio = intersection_area / min(box1_area, box2_area)\n",
    "        \n",
    "        return overlap_ratio >= overlap_threshold\n",
    "    \n",
    "    def process_video(self, video_path, output_path, fps=None):\n",
    "        \"\"\"Process video with guaranteed vertical output.\"\"\"\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error: Could not open video {video_path}\")\n",
    "            return\n",
    "            \n",
    "        # Get original video properties\n",
    "        orig_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        orig_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        # Force vertical output dimensions (height > width)\n",
    "        output_width = min(orig_width, orig_height)\n",
    "        output_height = max(orig_width, orig_height)\n",
    "        \n",
    "        # Set output FPS\n",
    "        if fps is None:\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        \n",
    "        # Video writer with vertical orientation\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (output_width, output_height))\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            # Process frame (automatically rotates to vertical)\n",
    "            processed_frame = self.process_frame(frame)\n",
    "            \n",
    "            # Ensure output matches desired dimensions\n",
    "            if processed_frame.shape[1] != output_width or processed_frame.shape[0] != output_height:\n",
    "                processed_frame = cv2.resize(processed_frame, (output_width, output_height))\n",
    "            \n",
    "            out.write(processed_frame)\n",
    "            cv2.imshow('Helmet Detection', processed_frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "                \n",
    "        cap.release()\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(f\"Vertical video saved to {output_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize with your paths\n",
    "    detector = HelmetDetectionSystem(\n",
    "        model_path=r'C:\\Users\\Daud\\Downloads\\traffic_safety_yolov8\\best.pt',\n",
    "        class_names=['helmet', 'license_plate', 'motorcyclist']\n",
    "    )\n",
    "    \n",
    "    # Process video with vertical output\n",
    "    detector.process_video(\n",
    "        video_path=r'C:\\Users\\Daud\\Downloads\\traffic_safety_yolov8\\5 s.mp4',\n",
    "        output_path=r'C:\\Users\\Daud\\Downloads\\traffic_safety_yolov8\\1output_vertical.mp4'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "isSourceIdPinned": true,
     "modelId": 427687,
     "modelInstanceId": 409841,
     "sourceId": 521116,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
